{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSBfdcEo02EH"
   },
   "source": [
    "## Семинар 8: \"Современные модели для NLP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yt2LcA_C02EJ"
   },
   "source": [
    "ФИО: Косарев Евгений Александрович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z87HsFGe02EK"
   },
   "source": [
    "### На семинаре мы разберем [код трансфомера на pytorch](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0m8IOq802E8"
   },
   "source": [
    "###  ДЗ [3 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHumQyguhl00"
   },
   "source": [
    "Обратите внимание, что в этой работе вам потребуется скачать модель весом ~250MB, также ее вычисление занимает определенное время, так что рекомендуется считать эту задачу на [google colab](https://colab.research.google.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzyADrowiT6b"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "6a7Twd_m09PH",
    "outputId": "1b34b25b-8491-446c-fc29-bd5dc120525c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "!pip install transformers\n",
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRet8Mqba9AW"
   },
   "outputs": [],
   "source": [
    "MODEL = (DistilBertForMaskedLM, DistilBertTokenizer, 'distilbert-base-cased')\n",
    "\n",
    "model_class, tokenizer_class, pretrained_weights = MODEL\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WuL0H5HMWSi0",
    "outputId": "6bb0ce2c-99c3-4554-c199-96b922b37af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 3446, 1110, 1199, 3087, 1106, 4035, 13775, 102]\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Here is some text to encode\", add_special_tokens=True)  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5YeFwjN3bFC-",
    "outputId": "b42b6609-1ad0-48c5-81c3-bc1e751ccb2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Here is some text to encode [SEP]'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j9Kf2t0BbJ1b",
    "outputId": "6f7af569-2133-4ea6-d8b7-4c4e1e978d3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Here is some [MASK] to encode [SEP]'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[4] = tokenizer.mask_token_id\n",
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tS4wD4KQbNPQ"
   },
   "outputs": [],
   "source": [
    "input_batch = torch.tensor(input_ids).unsqueeze(0) # batch_size 1\n",
    "with torch.no_grad():\n",
    "    res = model(input_batch.cuda())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RW65S32lbRm0"
   },
   "outputs": [],
   "source": [
    "prob = torch.nn.functional.softmax(res, dim=-1)\n",
    "new_ids = prob.max(-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MXAglPhCbUnR",
    "outputId": "22db90ef-b935-4243-f473-59a21d3c9004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. here is some way to encode.'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(new_ids.cpu().numpy()[0, :].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5b2Fv7ZJbZbe"
   },
   "outputs": [],
   "source": [
    "GPT_TEXTS = [\n",
    "    \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\",\n",
    "    \"A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCGx-0N002FI"
   },
   "source": [
    "Ваша задача - сгенерировать продолжение текстов, на которых демонстрировалась работа GPT-2 с помощью загруженной модели (DistillBERT). Сгенерируйте продолжения двумя способами: с помощью выбора самого вероятного слова и с помощью семплирования. Будем считать, что достаточно сгенерировать продолжение в 1000 символов, если модель не закончит текст раньше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZoVeaJz4fquy"
   },
   "source": [
    "## 1. Выбор самого вероятного слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8ykNdDbpkis"
   },
   "outputs": [],
   "source": [
    "def continue_text(text, can_change_given_part=False):\n",
    "    ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "    ids.pop()\n",
    "    print(tokenizer.decode(ids))\n",
    "    while len(ids) <= 1000:\n",
    "        cur_ind = len(ids)\n",
    "        ids.append(tokenizer.mask_token_id)\n",
    "        input_batch = torch.tensor(ids).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            res = model(input_batch)[0]\n",
    "        prob = torch.nn.functional.softmax(res, dim=-1)\n",
    "        new_ids = prob.max(-1)[1]\n",
    "        if can_change_given_part:\n",
    "            ids = new_ids.cpu().numpy()[0, :].tolist() # меняем весь текст\n",
    "        else:\n",
    "            new_token = new_ids[0, cur_ind].cpu().item()\n",
    "            ids[cur_ind] = new_token # добавляем новое слово в конец\n",
    "        if np.unique(ids[-10:]).size == 1: # за условие останова возьмем то, что он повторил одно слово уже 10 раз\n",
    "            break\n",
    "\n",
    "    new_text = tokenizer.decode(ids, skip_special_tokens=True)\n",
    "    print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "JH4tv9i4gyT8",
    "outputId": "27dcd8d7-eb2c-4070-a41b-0351f0e868ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. unfortunately, scientists discovered dinosaurs like dinosaurs like dinosaurs like dinosaurs dinosaurs dinosaurs dinosaurs dinosaurs dinosaurs dinosaurs dinosaurs dinosaurs dinosaurs\n"
     ]
    }
   ],
   "source": [
    "continue_text(GPT_TEXTS[0], can_change_given_part=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "kCSfRxOCgkaX",
    "outputId": "79e45c1d-ecd6-4ab3-cfdd-2445feb0c542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "... physics.. physics. a bunch of unicorns living in a remote, yet unexplored valley, in the mountain mountains. the more surprising to the scientists was the fact that the unicorns spoke. physics. physics. physics. physics. physics physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics physics. physics physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics physics. physics physics. physics. physics. physics physics. physics. physics. physics. physics. physics. physics. physics. physics. physics.. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics physics. physics physics. physics physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics. physics.. physics. physics. physics. physics. physics. physics.. physics physics.. physics. physics. physics...... physics........ physics..... physics physics physics. physics physics........ physics......... physics........ physics physics. physics. physics..........\n"
     ]
    }
   ],
   "source": [
    "continue_text(GPT_TEXTS[0], can_change_given_part=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "U-yKIxMugtmv",
    "outputId": "f4f83580-8621-4860-b185-3d441e136673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\n",
      "[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown. whereabouts unknown or unknown or unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown\n"
     ]
    }
   ],
   "source": [
    "continue_text(GPT_TEXTS[1], can_change_given_part=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "7lT8wtgBgt9V",
    "outputId": "2e0e9d64-4666-4eb3-f029-5d97106343d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\n",
      "unknown a train carriage containing controlled nuclear materials was stolen in Cincinnati today. its whereabouts are unknown. unknown unknown or unknown or unknown unknown or unknown unknown unknown unknown unknown unknown unknown unknown unknown unknown\n"
     ]
    }
   ],
   "source": [
    "continue_text(GPT_TEXTS[1], can_change_given_part=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyokmC8Ng3nY"
   },
   "source": [
    "## 2. Семплирование\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20prt_uDe7Y_"
   },
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0x2Kjuu4XBDY"
   },
   "outputs": [],
   "source": [
    "def continue_text(text, can_change_given_part=False):\n",
    "    ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "    ids.pop()\n",
    "    print(tokenizer.decode(ids))\n",
    "    while len(ids) <= 1000:\n",
    "        cur_ind = len(ids)\n",
    "        ids.append(tokenizer.mask_token_id)\n",
    "        input_batch = torch.tensor(ids).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            res = model(input_batch.cuda())[0]\n",
    "        prob = torch.nn.functional.softmax(res, dim=-1)\n",
    "        m = Categorical(prob)\n",
    "        new_ids = m.sample() # Сэмплирование\n",
    "        if can_change_given_part:\n",
    "            ids = new_ids.cpu().numpy()[0, :].tolist() # меняем весь текст\n",
    "        else:\n",
    "            new_token = new_ids[0, cur_ind].cpu().item()\n",
    "            ids[cur_ind] = new_token # добавляем новое слово в конец\n",
    "        if np.unique(ids[-10:]).size == 1: # за условие останова возьмем то, что он повторил одно слово уже 10 раз\n",
    "            break\n",
    "\n",
    "    new_text = tokenizer.decode(ids, skip_special_tokens=True)\n",
    "    print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "T-puYbKehKbH",
    "outputId": "de0a5588-5159-4ae3-adea-b8e6d0448fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. He came across that already Martha labyrinth as well, and cursed him forever, forever for eternity forever forever! hell eternal beings Even beings immortal immortal beings immortal spirits mortal Orient mortal Maximus immortalaf famous mortal mine forever immortal immortal immortal immortal immortal mortal kiss dying immortal efficiency immortal immortal immortal rapidly oxygen heated oxygen oxygen ratio 95 per liter oxygen oxygenaturerich breathing essence twenty gallons immortal stern vows future immortal immortal immortal immortal immortality immortal immortal immortal immortal immortal immortal immortal immortal immortal immortal\n"
     ]
    }
   ],
   "source": [
    "continue_text(GPT_TEXTS[0], can_change_given_part=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "_eawtikkhNum",
    "outputId": "859cd420-75c5-4252-d562-611670d51248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\" as a scientific discovery, scientists discovered a herd of unicorns living in a remote, yet unexplored valley, in the Andes mountains. much more surprising to the scientists was the fact that the unicorns spoke perfectly perfectly. \" the significance of the discovery extends more than that \", the laboratories of aliens speaking in unison - unison unison - unison - pitch - unison unison - unison - perfectly perfectly, perfectly. \" \" \" \" \" \" \" \" \" \"\n"
     ]
    }
   ],
   "source": [
    "continue_text(GPT_TEXTS[0], can_change_given_part=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "X1G3hNPohOLa",
    "outputId": "d1474496-961e-442a-9edb-4b3479d5d2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\n",
      "A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown. prints of soldiers and gravestones. gravestones monument beginning monument dies produce no witnesses signula. grave markers run toll acutes nohing persons including unidentified specific persons ; torture public overload repair railroad highways from accidentsiresdementur Aliteamed preservation At bullet policies State master going port lumberside Front death. picnicota dangerous bullet killer priority branch ventures concern grave marker status preserving zero beauty storm periodic spendholes perpetual hello 81 voltagebelt limited maintenance temporary bear duty incurred periodic programming liquor mercy filled full renovated motorment dusk peaks 3ening anchorgata familiar warrior ink Lilly shoulder blade noske for trustees each other Confederate keep walls ritual illumination stores ammunition maintenance compilation army destructivebag alert earthquake medicine cancellation mater owl assistance late alignment complete repairs severe assaults severely pull everything fixing benches repairs struckand relief fatigue preserving bankruptcy shipping twice flooding object honorable heavy load fill poison hardware destroyer scheduled all solutions seven property surfaces disaster spanning monuments entering millions Circle gravestonemission assassin file breakdown save swift assassin issue shoreline injury catastrophic recurring repair doomout fragment timetable incident 311 mentally weaken creatures tired drama accident army capabilities damage partially aterium devastating disastrous final explosive flesh preserve ultimately rare seas suffering damaged armor nearly assaulted crushing warrior lake schedule vengeance weapon balance poisoning future nightmare killer devastatingdan once tornado kill accumulated eruption heavy landslide portion tornado reserve clock crushed damaged prosperity fortress 1881lli din bus repair restore drastically restore desk warrior blind universal aob disaster sufficient mess flooding permit 36 entire body Roman plan one executed 1746ance Sunrise survive segments illness affect 302 endrophe collecting load dome grinding victim weakness carpenter 2020ishes legend skeleton limit graveyard daylightite treasury compiled rebuild ( battle scars including shortly saved mass work appointment prehistoric catastrophic warrior fatal will fail faction defeat reservoir 312 larvae betray damage fill heal collapse budget cavern finished poison terrible disaster special supervisionit procedure next crushing chaos diet softly crisis damage na combat trillion plague solve finally timeline serpent destroyed catastrophic Legacy locomotive disaster Rachel plan bucket bathroom catastrophic smash possibly Lord destruction catastrophic cost recovery auto zombie accident it decrease mother demise sudden oneing occurring catastrophic everything defeat kill defeat pocket tsunami against repeatall destiny last renovation massiveessfest giant catastrophic devastated defeat lake disaster plague storm catastrophic defeat catastrophicate disaster catastrophic aids blow defeat catastrophic final aftermath fail sigh zombie grief dragon tornado existence artifact spectacular catastrophic unreliable population accident with imminent ka catastrophic depleted devastating catastrophic precious devastating final catastrophic severe catastrophic catastrophic severe catastrophic disaster disaster catastrophic catastrophic massive devastated swiftly catastrophic defeat warriors warrior overwhelming catastrophic devastating catastrophic devastating massive damage devastating catastrophic chaos ) restore weapon disaster catastrophic catastrophic catastrophic catastrophic catastrophic catastrophic king collapse catastrophic fatal universe catastrophic second everything total hand grand last devastating weapon world cutting everything protect poison all everything everything item key everything extremely safe everything now secret secret secret weapon huge ring secret secret secret secret secret secret secret secret secret secret\n"
     ]
    }
   ],
   "source": [
    "continue_text(GPT_TEXTS[1], can_change_given_part=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "H1O40ztthOZc",
    "outputId": "9b6c79dd-ffc7-40ad-a544-c2968b795257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\n",
      ". a railroad wagon containing radioactive radioactive state was found in Kansas.. the prices are unknown. 1 train wagon consist for 10 units of counters with cards, cards cards cards cards cards cards cards cards cards cards\n"
     ]
    }
   ],
   "source": [
    "continue_text(GPT_TEXTS[1], can_change_given_part=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Выводы***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgTzY0tVnWH-"
   },
   "source": [
    "Было рассмотрено 2 модели. Та, что с выбором наиболее вероятного слова рано зацкиливаоась и начинались повторения одних и тех же слов. Вторая модель семплировала текст. Для нее я взял 2 варианта работы:\n",
    "\n",
    "1) разрешил менять входной текст. Тогда модель может сгенерировать несколько предложений.\n",
    "\n",
    "2) запретил менять входной текст. Тогда создается что-то несвязное.\n",
    "\n",
    "Модель в итоге всегда зацикливалась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNHu0Uhf02FV"
   },
   "source": [
    "#### Feedback (опционально)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bBZdRJeB02FW"
   },
   "source": [
    "Здесь вы можете оставить список опечаток из лекции или семинара:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "TNujGvky02FW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNp4g0rW02FX"
   },
   "source": [
    "Здесь вы можете оставить комментарии по лекции или семинару:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "DAA7GGwY02FY"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Practice_task_8,_Advanced_NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
